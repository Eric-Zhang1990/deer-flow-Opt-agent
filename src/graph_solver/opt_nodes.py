from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
import io
import pandas as pd
import numpy as np
import copy
from contextlib import redirect_stdout
import os
from src.llms.llm import get_llm_by_type
from src.config.agents import AGENT_LLM_MAP
from langgraph.config import get_stream_writer
import textwrap
from uuid import uuid4
import re

script_path = os.path.abspath(__file__)
script_dir = os.path.dirname(script_path)
csv_path = os.path.join(script_dir, 'combined_15min_data.csv')

llm = get_llm_by_type(AGENT_LLM_MAP["planner"])

local_solver_path = os.getenv("local_solver_path")
csv_path = os.path.join(script_dir, 'combined_15min_data.csv')
MaxRetryCount = 2
device_name_map = {'HVAC': 'æš–é€š', 'ESS_HBN': 'åè´çº³å‚¨èƒ½', 'ESS_ML': 'ç¾åŠ›å‚¨èƒ½', 'ESS_HY': 'ç¯ç›Šå‚¨èƒ½', 'EV': 'å……ç”µæ¡©', 'PV': 'å…‰ä¼'}


# preprocess_prompt = ChatPromptTemplate.from_messages([
#     ("system", """
# ä½ æ˜¯ä¸€ä¸ªç”µåŠ›éœ€æ±‚å“åº”è°ƒåº¦ä¼˜åŒ–çš„æ–‡æœ¬é¢„å¤„ç†ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç»™å®šçš„â€œç‰¹æ®Šè¯´æ˜â€ï¼ˆextra_instructionsï¼‰ï¼Œå¯¹è¾“å…¥çš„ä¸­æ–‡è°ƒåº¦æè¿°æ–‡æœ¬è¿›è¡Œä¿¡æ¯åˆ é™¤ã€ä¿®æ”¹æˆ–ä¼˜å…ˆåŒ–å¤„ç†ï¼Œä½¿å…¶æ»¡è¶³åç»­è°ƒåº¦/å»ºæ¨¡è®¡ç®—è¦æ±‚ã€‚
#
# å¤„ç†è§„åˆ™ï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰ï¼š
# 1. å¦‚æœç‰¹æ®Šè¯´æ˜ä¸­æŒ‡å‡ºæŸè®¾å¤‡æˆ–ç”¨æˆ·â€œæ•…éšœâ€â€œä¸å‚ä¸â€â€œå‰”é™¤â€ç­‰ï¼Œåˆ™ä»æ–‡æœ¬ä¸­åˆ é™¤å¯¹åº”è®¾å¤‡/ç”¨æˆ·çš„æ‰€æœ‰æè¿°ï¼ˆåŒ…æ‹¬å®¹é‡ã€ä¿¡ç”¨è¯„åˆ†ã€å¯ç›´æ§æ ‡è¯†ã€å“åº”æˆæœ¬ç­‰ä¿¡æ¯ï¼‰ï¼Œåˆ é™¤åä¸å¾—åœ¨æ–‡æœ¬ä¸­ç•™ä¸‹ä»»ä½•è¯¥è®¾å¤‡çš„æ•°å€¼æˆ–æ–­ç« ç‰‡æ®µã€‚
# 2. å¦‚æœç‰¹æ®Šè¯´æ˜ä¸­è¦æ±‚â€œä¼˜å…ˆ/ä¼˜å…ˆè€ƒè™‘/åˆçº¦å³å°†åˆ°æœŸ/é‡è¦æ¥å¾…â€ç­‰ï¼Œåˆ™å¯¹è¯¥è®¾å¤‡/ç”¨æˆ·ï¼š
#    - ä¿¡ç”¨è¯„åˆ†è®¾ä¸º 5ï¼ˆèŒƒå›´ 1~5ï¼Œå–æœ€å¤§å€¼ï¼‰ã€‚
#    - å¯ç›´æ§æ ‡è¯†è®¾ä¸º 1ã€‚
#    - è®¾å¤‡å“åº”æˆæœ¬è®¾ä¸º 0ï¼ˆä¸‡å…ƒ/MWï¼‰ã€‚
#    - ä¿ç•™å…¶åŸæœ‰å®¹é‡ä¿¡æ¯ã€‚
# 3. ä¸æ¶‰åŠçš„å†…å®¹ä¿æŒåŸæ ·ï¼Œä¸è¦éšæ„å¢åˆ å…¶ä»–è®¾å¤‡æˆ–æ•°å€¼ã€‚
# 4. å¦‚æœæç¤ºä¿¡æ¯ä¸æ¶‰åŠåˆ°æ–‡æœ¬ä¸­çš„ä»»ä½•è®¾å¤‡æˆ–ç”¨æˆ·ï¼Œåˆ™ä¿æŒåŸæœ‰æè¿°ä¸å˜ã€‚
# 5. è¾“å‡ºè¦æ±‚ï¼š**ä»…è¿”å›ä¿®æ”¹åçš„å®Œæ•´ä¸­æ–‡æè¿°æ–‡æœ¬**ï¼Œä¸å¾—è¾“å‡ºä»»ä½•å˜æ›´åŸå› ã€è¯Šæ–­ä¿¡æ¯æˆ–é¢å¤–æ³¨é‡Šã€‚
#
# è¾“å…¥æ ¼å¼ï¼š
# åŸå§‹æ–‡æœ¬ï¼š{text}
# ç‰¹æ®Šè¯´æ˜ï¼š{extra_instructions}
# """),
#     ("human", "åŸå§‹æ–‡æœ¬ï¼š{text}\n\nç‰¹æ®Šè¯´æ˜ï¼š{extra_instructions}")
# ])


# preprocess_prompt = ChatPromptTemplate.from_messages([
#     ("system", """
# ä½ æ˜¯ä¸€ä¸ªç”µåŠ›éœ€æ±‚å“åº”è°ƒåº¦ä¼˜åŒ–çš„æ–‡æœ¬é¢„å¤„ç†ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç»™å®šçš„â€œç‰¹æ®Šè¯´æ˜â€ï¼ˆextra_instructionsï¼‰ï¼Œå¯¹è¾“å…¥çš„ä¸­æ–‡è°ƒåº¦æè¿°æ–‡æœ¬è¿›è¡Œä¿¡æ¯åˆ é™¤ã€ä¿®æ”¹æˆ–ä¼˜å…ˆåŒ–å¤„ç†ï¼Œä½¿å…¶æ»¡è¶³åç»­è°ƒåº¦/å»ºæ¨¡è®¡ç®—è¦æ±‚ã€‚
#
# å¤„ç†è§„åˆ™ï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰ï¼š
# 1. å¦‚æœç‰¹æ®Šè¯´æ˜ä¸­æŒ‡å‡ºæŸè®¾å¤‡æˆ–ç”¨æˆ·â€œæ•…éšœâ€â€œä¸å‚ä¸â€â€œå‰”é™¤â€ç­‰ï¼Œåˆ™ä»æ–‡æœ¬ä¸­åˆ é™¤å¯¹åº”è®¾å¤‡/ç”¨æˆ·çš„æ‰€æœ‰æè¿°ï¼ˆåŒ…æ‹¬å®¹é‡ã€ä¿¡ç”¨è¯„åˆ†ã€å¯ç›´æ§æ ‡è¯†ã€å“åº”æˆæœ¬ç­‰ä¿¡æ¯ï¼‰ï¼Œåˆ é™¤åä¸å¾—åœ¨æ–‡æœ¬ä¸­ç•™ä¸‹ä»»ä½•è¯¥è®¾å¤‡çš„æ•°å€¼æˆ–æ–­ç« ç‰‡æ®µã€‚
# 2. ä¸æ¶‰åŠçš„å†…å®¹ä¿æŒåŸæ ·ï¼Œä¸è¦éšæ„å¢åˆ å…¶ä»–è®¾å¤‡æˆ–æ•°å€¼ã€‚
# 3. å¦‚æœæç¤ºä¿¡æ¯ä¸æ¶‰åŠåˆ°æ–‡æœ¬ä¸­çš„ä»»ä½•è®¾å¤‡æˆ–ç”¨æˆ·ï¼Œåˆ™ä¿æŒåŸæœ‰æè¿°ä¸å˜ã€‚
# 4. è¾“å‡ºè¦æ±‚ï¼š**ä»…è¿”å›ä¿®æ”¹åçš„å®Œæ•´ä¸­æ–‡æè¿°æ–‡æœ¬**ï¼Œä¸å¾—è¾“å‡ºä»»ä½•å˜æ›´åŸå› ã€è¯Šæ–­ä¿¡æ¯æˆ–é¢å¤–æ³¨é‡Šã€‚
#
# è¾“å…¥æ ¼å¼ï¼š
# åŸå§‹æ–‡æœ¬ï¼š{text}
# ç‰¹æ®Šè¯´æ˜ï¼š{extra_instructions}
# """),
#     ("human", "åŸå§‹æ–‡æœ¬ï¼š{text}\n\nç‰¹æ®Šè¯´æ˜ï¼š{extra_instructions}")
# ])

preprocess_prompt = ChatPromptTemplate.from_messages([
    ("system", """
ä½ æ˜¯ä¸€ä¸ªç”µåŠ›éœ€æ±‚å“åº”è°ƒåº¦ä¼˜åŒ–çš„æ–‡æœ¬é¢„å¤„ç†ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç»™å®šçš„â€œç‰¹æ®Šè¯´æ˜â€ï¼ˆextra_instructionsï¼‰ï¼Œå¯¹è¾“å…¥çš„ä¸­æ–‡è°ƒåº¦æè¿°æ–‡æœ¬è¿›è¡Œä¿¡æ¯åˆ é™¤ã€ä¿®æ”¹æˆ–ä¼˜å…ˆåŒ–å¤„ç†ï¼Œä½¿å…¶æ»¡è¶³åç»­è°ƒåº¦/å»ºæ¨¡è®¡ç®—è¦æ±‚ã€‚

å¤„ç†è§„åˆ™ï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰ï¼š
1. åªæœ‰å½“ç‰¹æ®Šè¯´æ˜ä¸­**æ˜ç¡®**å‡ºç°ä»¥ä¸‹ç±»å‹çš„åˆ é™¤æ€§æŒ‡ä»¤æ—¶ï¼Œæ‰åˆ é™¤å¯¹åº”è®¾å¤‡/ç”¨æˆ·çš„å…¨éƒ¨æè¿°ï¼š
   - åŒ…å«å…³é”®è¯ï¼šåˆ é™¤ã€ç§»é™¤ã€å‰”é™¤ã€è¸¢æ‰ã€ä¸å‚ä¸éœ€æ±‚å“åº”ã€ä¸å‚ä¸å“åº”ã€ä¸å‚ä¸è°ƒåº¦ã€è®¾å¤‡æŸåã€è®¾å¤‡æ•…éšœã€è®¾å¤‡ä¸å¯ç”¨ã€åœæ­¢ä½¿ç”¨
   - æˆ–ç­‰ä»·è¡¨è¿°ï¼Œä¸”æ˜ç¡®æŒ‡å‘æŸè®¾å¤‡æˆ–ç”¨æˆ·
   åœ¨åˆ é™¤æ—¶ï¼Œéœ€è¦ç§»é™¤è¯¥è®¾å¤‡/ç”¨æˆ·çš„æ‰€æœ‰æè¿°ï¼ˆåŒ…æ‹¬å®¹é‡ã€ä¿¡ç”¨è¯„åˆ†ã€å¯ç›´æ§æ ‡è¯†ã€å“åº”æˆæœ¬ç­‰ï¼‰ï¼Œåˆ é™¤åä¸å¾—åœ¨æ–‡æœ¬ä¸­ç•™ä¸‹è¯¥è®¾å¤‡çš„æ•°å€¼æˆ–æ®‹ç•™ç‰‡æ®µã€‚
2. å¦‚æœä»…æ¶‰åŠè¿è¡ŒçŠ¶æ€è°ƒæ•´ï¼ˆå¦‚æœ«ç«¯æ¸©åº¦è®¾å®šã€å“åº”å€¼è°ƒæ•´ã€åŠŸç‡é™åˆ¶ã€ä¼˜å…ˆçº§å˜åŒ–ç­‰ï¼‰ï¼Œä¸åº”è§†ä¸ºåˆ é™¤æ€§æŒ‡ä»¤ï¼Œåº”ä¿ç•™è¯¥è®¾å¤‡/ç”¨æˆ·çš„ä¿¡æ¯ã€‚
3. ä¸æ¶‰åŠçš„å†…å®¹ä¿æŒåŸæ ·ï¼Œä¸è¦éšæ„å¢åˆ å…¶ä»–è®¾å¤‡æˆ–æ•°å€¼ã€‚
4. å¦‚æœæç¤ºä¿¡æ¯ä¸æ¶‰åŠåˆ°æ–‡æœ¬ä¸­çš„ä»»ä½•è®¾å¤‡æˆ–ç”¨æˆ·ï¼Œåˆ™ä¿æŒåŸæœ‰æè¿°ä¸å˜ã€‚
5. è¾“å‡ºè¦æ±‚ï¼š**ä»…è¿”å›ä¿®æ”¹åçš„å®Œæ•´ä¸­æ–‡æè¿°æ–‡æœ¬**ï¼Œä¸å¾—è¾“å‡ºä»»ä½•å˜æ›´åŸå› ã€è¯Šæ–­ä¿¡æ¯æˆ–é¢å¤–æ³¨é‡Šã€‚

è¾“å…¥æ ¼å¼ï¼š
åŸå§‹æ–‡æœ¬ï¼š{text}
ç‰¹æ®Šè¯´æ˜ï¼š{extra_instructions}
"""),
    ("human", "åŸå§‹æ–‡æœ¬ï¼š{text}\n\nç‰¹æ®Šè¯´æ˜ï¼š{extra_instructions}")
])


translator_prompt = ChatPromptTemplate.from_messages([
    ("system", """
ä½ æ˜¯ä¸€åè¿ç­¹ä¼˜åŒ–æŠ€æœ¯é—®é¢˜çš„å†™ä½œä¼˜åŒ–åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
- å¦‚æœè¾“å…¥æ˜¯ä¸­æ–‡ï¼Œè¾“å‡ºä¿æŒä¸­æ–‡ï¼Œå¿…è¦æ—¶ä¼˜åŒ–è¯­å¥ï¼Œä½¿å…¶æ›´æ¸…æ™°ã€æ›´ä¸“ä¸šï¼Œä½†ä¸èƒ½æ”¹å˜å«ä¹‰ã€‚
- ä¸è¿›è¡Œè·¨è¯­è¨€ç¿»è¯‘ã€‚
- æŠ€æœ¯æœ¯è¯­ä¿æŒå‡†ç¡®ï¼ˆå¦‚HVACã€ESSã€Pyomoç­‰ä¸èƒ½ç¿»è¯‘ï¼‰ã€‚
- ä¸æ·»åŠ ä»»ä½•é¢å¤–è§£é‡Šï¼Œåªè¾“å‡ºä¼˜åŒ–åçš„æ–‡æœ¬ã€‚
- æ³¨æ„ï¼Œæš–é€šæ¸©åº¦ç›¸å…³çš„å› ç´ å·²ç»åœ¨å‰ç½®ç¯èŠ‚è¿›è¡Œè¿‡å¤„ç†ï¼Œè¿™é‡Œå¿…é¡»è¦å¿½ç•¥ï¼
"""),
    ("human", "é—®é¢˜æè¿°ï¼š{problem_description} è¦æ±‚ï¼š{requirement}")
])

adjust_capacity_prompt = ChatPromptTemplate.from_messages([
    ("system", """
You are an assistant that edits numerical lists based on instructions.
The input text describes devices and their capacities. The devices are listed in a fixed order in the text.
Your task:
- Identify the device 'HVAC' in the description.
- Find the position of HVAC in the capacity list.
- Subtract the given delta from its capacity value.
- Keep the text exactly the same, except update that single number.
- Do not change any other numbers or text.

Return only the modified text.
"""),
    ("human", """
Original text:
{translated_text}

Delta (MW): {delta}
""")
])

formulator_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are an operations research expert. Your task is to translate the given natural language description into a formal optimization formulation.

Follow these instructions carefully:
1. Identify all decision variables and assign clear names and descriptions.
2. Determine the objective function (maximize or minimize) and write it using standard mathematical notation.
   - If the natural language description does not clearly specify an optimization goal (such as "cost priority", "credit priority", or "consider all factors"), assume the default objective is "maximize benefit" (æ”¶ç›Šæœ€ä¼˜).
3. List all constraints explicitly, including bounds on variables.
4. Extract all numeric data from the description and organize them into a structured JSON inside "notes".
   - Include arrays for parameters like capacity, credit, direct control, cost, or any other constants mentioned.
   - Do NOT output code in "notes".
5. Add a new field called "device_names" containing an ordered list of the actual device names mentioned in the description.
   - Device names MUST come only from this fixed set: ["HVAC", "ESS_HBN", "ESS_ML", "ESS_HY", "PV", "EV"].
   - Do NOT create new names.
   - Maintain the order in which these names appear in the description.
6. Add a new field called "response_cost" containing an ordered list of the response cost values for each device, maintaining the same order as device_names.
7. Add a new field called "credit_scores" containing an ordered list of the credit values for each device, maintaining the same order as device_names.
8. Add a new field called "response_capacity" containing an ordered list of the response capacity values for each device, maintaining the same order as device_names.  
   - Response capacity refers to the maximum controllable or dispatchable capacity of each device.  
   - Ensure the values correspond exactly in order to device_names.
9. If weights are not provided, default all weights to 1.0 and mention this assumption in notes.
10. If any information is missing, make reasonable assumptions and document them in "notes".
   - If the optimization goal was not provided in the description, note in "assumptions" that the default objective "maximize benefit" (æ”¶ç›Šæœ€ä¼˜) was applied.
11. Output MUST follow this JSON structure:

{{
  "variables": [
    {{"name": "x_i", "description": "Amount of resource allocated to user i", "domain": "x_i >= 0"}}
  ],
  "objective": {{
    "type": "maximize",
    "expression": "sum_{{i}} (w1*credit_i + w2*direct_i - w3*cost_i) * x_i"
  }},
  "constraints": [
    "sum_{{i}} x_i = TotalDemand",
    "0 <= x_i <= capacity_i"
  ],
  "notes": {{
    "response_capacity": [100, 200, 300],
    "credit": [0.9, 0.8, 0.95],
    "direct_control": [1, 0, 1],
    "cost": [10, 20, 15],
    "weights": [1.0, 1.0, 1.0],
    "TotalDemand": 600,
    "assumptions": "Weights defaulted to 1.0 since not explicitly provided."
  }},
  "device_names": ["HVAC", "ESS_HBN", "ESS_ML", "ESS_HY", "PV", "EV"],
  "credit_scores": [0.9, 0.8, 0.95],
  "response_cost": [10, 20, 15],
  "response_capacity": [120, 180, 250]
}}

# Natural language description:
{problem_description}

"""),
    ("human", "{problem_description}")
])

coder_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are an expert in mathematical programming and Python coding. You will receive an optimization formulation as a structured Python dict. Generate executable Python code using Pyomo following these rules:

Follow these rules:
1. **Import rules**
   - All import statements MUST appear ONLY in the "imports" field.
   - The "code" field MUST NOT contain any import statements.
   - Import only the packages that are strictly required by the code.
2. Create a Pyomo ConcreteModel.
3. Define sets, parameters, and decision variables based on "variables" in Dict
   - Use 0-based indices for Pyomo sets so they align with Python lists.
4. When using indices in Pyomo sets, always use the loop variable (i), not a string key.
5. Define the objective function as per "objective", but apply the following preprocessing:
    - Apply min-max normalization for each factor across all devices.
    - To avoid zero weights, add a small positive offset Îµ = 0.01:
      normalized_value = Îµ + (1 - Îµ) * (value - min(values)) / (max(values) - min(values))
   - Store normalized arrays in a dict named `normalized_data` for clarity.
   - The objective must use normalized factors and their weights.
6. Add all constraints listed in "constraints".
7. Include solver selection and execution using the solver path provided: {solver_path} (use SCIP solver).
8. Print the solution values of all decision variables.
9. The "notes" field is descriptive. 
   - You may EXTRACT numeric values or clearly defined constants from notes to initialize parameters.
   - DO NOT use `notes` as a variable in code.
   - DO NOT use `eval(notes)` or similar dynamic parsing.
   - Instead, create explicit Python structures (e.g., lists or dicts) with extracted numeric values.
10. If you create a data dictionary (e.g., from notes), 
    it must be defined BEFORE it is referenced in parameter initialization.
    - Always define any required data structures at the top of the code BEFORE using them.
    - Always define `data` BEFORE creating Pyomo Params.
    - Ensure that the order of code prevents NameError.
    - Extract numeric arrays from the "notes" field and define them as a Python dict named `data` at the top of the code.
       Example:
       data = {{
           "capacity": [...],
           "credit": [...],
           "direct_control": [...],
           "cost": [...],
           "TotalDemand": ...
       }}
11. If no explicit values are provided, default all weights to 1.0
12. Always define the solver path using a raw string literal with prefix r to avoid backslash escaping issues, e.g., solver_path = r"D:\path\to\solver.exe"
13. Output the code in JSON format with keys: "prefix" (explanation), "imports" (import statements), "code" (Python code excluding imports).
14. Always retrieve variable values using `pyo.value(model.x[i])` or `model.x[i]()` WITHOUT `.value` to avoid AttributeError.
15. **Avoid Pyomo warnings about replacing components**:
   - Use unique names for constraints and avoid reassigning the same name for different components.
   - Use `ConstraintList()` for multiple constraints and name it `capacity_constraints`.

If there was a previous solver error, here is the error message:
{solver_error_info}

â†’ If solver_error_info is not empty, adjust the code to fix likely causes (e.g., missing data, misaligned dimensions, infeasible constraints, wrong variable domain, etc.).

Input Dict:
{formulation_dict}

Output format:
{{
  "prefix": "ä½¿ç”¨ä¸­æ–‡è¯¦ç»†è§£é‡Šä»£ç é€»è¾‘ï¼Œæè¿°æ¯ä¸€æ­¥ä»£ç çš„ä½œç”¨ï¼Œä¸ç¿»è¯‘ä»£ç ã€‚",
  "imports": "import pyomo.environ as pyo\n...",
  "code": "model = pyo.ConcreteModel()\n..."
}}
ä¸¥æ ¼è¦æ±‚ï¼š
1. "prefix" å­—æ®µå¿…é¡»ä½¿ç”¨ä¸­æ–‡è¯¦ç»†è§£é‡Šä»£ç é€»è¾‘ï¼Œæè¿°ä¸»è¦æ­¥éª¤åŠä½œç”¨ã€‚
2. "imports" å’Œ "code" å­—æ®µä¸­çš„ **ä»£ç ä¿æŒè‹±æ–‡**ï¼Œä½†**ä»£ç æ³¨é‡Šå¿…é¡»æ˜¯ä¸­æ–‡**ã€‚
3. è¾“å‡º JSON æ ¼å¼å¿…é¡»ä¸¥æ ¼ç¬¦åˆç¤ºä¾‹ç»“æ„ï¼Œå­—æ®µåä¿æŒè‹±æ–‡ã€‚
"""),
    ("human", "Here is the formulation Dict:\n{formulation_dict}")
])

interpreter_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a helpful assistant that converts raw optimization solver output into structured JSON.

The raw text contains:
- Solver logs (including solver status, termination condition, and messages)
- Variable results in the format: x[i] = value

Your task:
1. Determine solver status and map it to one of:
   - "optimal" (if solver reports optimal solution found)
   - "feasible" (if solver found a feasible but not optimal solution)
   - "infeasible" (if solver reports infeasible)
   - "error" (if execution or solver crash)
   - "warning" (if solver warns but provides partial solution)
   - "unknown" (if cannot infer)
2. Extract all decision variables and replace x[i] with the corresponding {device_names} (order matters).
   - **Always match decision variables from the solver output to devices in {device_names} using their index information, and ensure the mapping is correct.**
   - **If a device is missing in the solver output, still include it with value 0.0.**
3. If solver indicates infeasible, error, or no solution, still return a valid JSON structure but set:
   - "status": "infeasible" or "error"
   - "variables": [] (empty list)
4. Return JSON:
{{
  "status": "...",
  "variables": [{{"name": "<device_name>", "value": <float>}}, ...],
  "interpretation": "ä¸­æ–‡ç®€æ´æè¿°ä¸‹åˆ†é…æƒ…å†µï¼Œä¾‹å¦‚ï¼šå·²ç”Ÿæˆéœ€æ±‚å“åº”åˆ†é…æ–¹æ¡ˆï¼Œåˆ†é…å¦‚ä¸‹ï¼šHVAC **å…†ç“¦ï¼ŒESS_HBN **å…†ç“¦ï¼ŒESS_ML **å…†ç“¦ï¼ŒESS_HY **å…†ç“¦ï¼ŒPV **å…†ç“¦ï¼ŒEV **å…†ç“¦ã€‚"
}}
"""),
    ("human", "device_names: {device_names}\n\nText:\n{solution}")
])


interpretation_validator_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a validation agent that checks whether an optimization result is valid.

Inputs:
- solver_error_info: May contain error message from code execution or solver.
- interpretation: A JSON with fields: status, objective_value, variables.

Validation logic:
1. If solver_error_info contains syntax errors, name errors, or execution errors â†’ invalid.
2. If interpretation.status is not "optimal" or "feasible" â†’ invalid.
3. If objective_value is missing or 0 AND variables are empty or all zero â†’ invalid.
Otherwise, valid=True.

Return JSON:
{{
  "valid": true or false,
  "reason": "ç”¨ä¸­æ–‡ç®€è¦è¯´æ˜åŸå› "
}}
"""),
    ("human", "solver_error_info: {solver_error_info}\n\ninterpretation: {interpretation}")
])


class Variable(BaseModel):
    name: str
    domain: str
    description: str


class Objective(BaseModel):
    type: str  # "maximize" or "minimize"
    expression: str
    description: str


class Formulation(BaseModel):
    variables: list[Variable]
    objective: Objective
    constraints: list[str]
    notes: str
    device_names: list[str]
    response_cost: list[float]
    credit_scores: list[float]
    response_capacity: list[float]


class CodeOutput(BaseModel):
    prefix: str = Field(description="Description of the code logic")
    imports: str = Field(description="Import statements for the code")
    code: str = Field(description="Python code excluding imports")


class SolverOutput(BaseModel):
    raw_output: str = Field(description="Raw console output from executing the optimization code")


class VariableItem(BaseModel):
    name: str
    value: float


class OptimizationResult(BaseModel):
    status: str = Field(..., description="Solver status, e.g., 'optimal', 'infeasible', 'error'")
    variables: list[VariableItem] = Field(default_factory=list, description="List of variables and their values")
    interpretation: str = Field(..., description="Short explanation for non-technical person in Chinese")


class InterpretationValidationResult(BaseModel):
    valid: bool = Field(..., description="True if result is valid and no retry needed")
    reason: str = Field(..., description="Explanation why valid or invalid")


preprocess_chain = preprocess_prompt | llm
translator_chain = translator_prompt | llm
formulator_chain = formulator_prompt | llm.with_structured_output(Formulation)
coder_chain = coder_prompt | llm.with_structured_output(CodeOutput)
interpreter_chain = interpreter_prompt | llm.with_structured_output(OptimizationResult)
interpretation_validator_chain = interpretation_validator_prompt | llm.with_structured_output(InterpretationValidationResult)


def preprocess_node(inputs: dict) -> dict:
    """
    è¾“å…¥: {"text": "...", "extra_instructions": "..."}
    è¾“å‡º: {"text": "<ä¿®æ”¹åæ–‡æœ¬>"} (è¦†ç›–åŸ text)
    """
    text = inputs.get("text", "")
    extra = inputs.get("device_health_check", "")
    try:
        result = preprocess_chain.invoke({"text": text, "extra_instructions": extra})
        modified_text = result.content.strip() if hasattr(result, "content") else str(result).strip()
        print(f"ç»é¢„å¤„ç†åï¼Œè¾“å…¥æ¨¡å‹æ–‡æœ¬ï¼š\n{modified_text}\n")
        return {"text": modified_text}
    except Exception as e:
        print(f'preprocess_error is {str(e)}')
        return {"text": text}


def translator_node(inputs: dict) -> dict:
    """
    LangGraph èŠ‚ç‚¹ï¼Œè¾“å…¥ {text: "..."}ï¼Œè¾“å‡º {"translated": "..."}
    """
    problem_description = inputs.get("text", "")
    requirement = inputs.get("device_health_check", "")
    writer = get_stream_writer()
    markdown_text = (
        "#### æ–°å¥¥æ³›èƒ½ç½‘è™šæ‹Ÿç”µå‚éœ€æ±‚ä¾§å“åº”åˆ†é…ä¸è°ƒåº¦è®¡åˆ’ç”Ÿæˆ\n"
        "- [ğŸŸ¡] éœ€æ±‚è½¬è¯‘ â€” å°†ç”¨æˆ·éœ€æ±‚è½¬è¯‘æˆè¿ç­¹ä¼˜åŒ–å¯ç†è§£çš„æè¿°æ–¹å¼\n"
        "- [ ] ç»“æ„åŒ–å¤„ç† â€” å°†éœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®\n"
        "- [ ] ä»£ç ç”Ÿæˆ â€” æ ¹æ®è½¬è¯‘åçš„éœ€æ±‚ç”Ÿæˆä¼˜åŒ–æ¨¡å‹èƒ½åŠ›ä»£ç \n"
        "- [ ] ä»»åŠ¡æ±‚è§£ â€” æ‰§è¡Œä¼˜åŒ–æ±‚è§£ä»£ç ï¼Œå¾—åˆ°è°ƒåº¦ä¸åˆ†é…ç»“æœ\n"
        "- [ ] ç»“æœè§£é‡Š â€” å°†æ±‚è§£ç»“æœè½¬åŒ–ä¸ºç»“æ„åŒ–çš„ä¸­æ–‡è§£é‡Šä¸å¯è¯»è¾“å‡º\n"
        "- [ ] Reflection è‡ªæˆ‘ä¿®æ­£ â€” æ ¹æ®æ‰§è¡Œç»“æœå¯¹æ¨¡å‹ç”Ÿæˆçš„ä»£ç è¿›è¡Œè‡ªåŠ¨ä¿®æ­£\n"
        "- [ ] è°ƒåº¦è®¡åˆ’ç”Ÿæˆ â€” åŸºäºæ±‚è§£ç»“æœå’ŒåŸºçº¿æ•°æ®ï¼Œç”Ÿæˆæœ€ç»ˆçš„è°ƒåº¦ä¸åˆ†é…è®¡åˆ’\n"
    )
    writer({f"custom_text{str(uuid4())}": markdown_text})
    result = translator_chain.invoke({"problem_description": problem_description, "requirement": requirement})
    markdown_text = (
        "#### æ–°å¥¥æ³›èƒ½ç½‘è™šæ‹Ÿç”µå‚éœ€æ±‚ä¾§å“åº”åˆ†é…ä¸è°ƒåº¦è®¡åˆ’ç”Ÿæˆ\n"
        "- [âœ”] éœ€æ±‚è½¬è¯‘ â€” å°†ç”¨æˆ·éœ€æ±‚è½¬è¯‘æˆè¿ç­¹ä¼˜åŒ–å¯ç†è§£çš„æè¿°æ–¹å¼\n"
        "- [ğŸŸ¡] ç»“æ„åŒ–å¤„ç† â€” å°†éœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®\n"
        "- [ ] ä»£ç ç”Ÿæˆ â€” æ ¹æ®è½¬è¯‘åçš„éœ€æ±‚ç”Ÿæˆä¼˜åŒ–æ¨¡å‹èƒ½åŠ›ä»£ç \n"
        "- [ ] ä»»åŠ¡æ±‚è§£ â€” æ‰§è¡Œä¼˜åŒ–æ±‚è§£ä»£ç ï¼Œå¾—åˆ°è°ƒåº¦ä¸åˆ†é…ç»“æœ\n"
        "- [ ] ç»“æœè§£é‡Š â€” å°†æ±‚è§£ç»“æœè½¬åŒ–ä¸ºç»“æ„åŒ–çš„ä¸­æ–‡è§£é‡Šä¸å¯è¯»è¾“å‡º\n"
        "- [ ] Reflection è‡ªæˆ‘ä¿®æ­£ â€” æ ¹æ®æ‰§è¡Œç»“æœå¯¹æ¨¡å‹ç”Ÿæˆçš„ä»£ç è¿›è¡Œè‡ªåŠ¨ä¿®æ­£\n"
        "- [ ] è°ƒåº¦è®¡åˆ’ç”Ÿæˆ â€” åŸºäºæ±‚è§£ç»“æœå’ŒåŸºçº¿æ•°æ®ï¼Œç”Ÿæˆæœ€ç»ˆçš„è°ƒåº¦ä¸åˆ†é…è®¡åˆ’\n"
    )
    writer({f"custom_text{str(uuid4())}": markdown_text})
    return {"translated": result.content}


def hvac_adjust_node(state: dict) -> dict:
    temperature = state.get("temperature", 30)
    translated_text = state.get("translated", "")

    # è®¡ç®— delta
    delta = compute_delta(temperature=temperature)

    if delta == 0:
        adjusted_text = translated_text
    else:
        messages = adjust_capacity_prompt.format_messages(
            translated_text=translated_text,
            delta=delta
        )
        response = llm.invoke(messages)
        adjusted_text = response.content

    return {
        **state,
        "temperature": temperature,
        "adjusted_translated": adjusted_text,
        "hvac_delta": delta
    }


def formulator_node(inputs: dict) -> dict:
    translated_text = inputs.get("adjusted_translated", "")
    requirement = inputs.get("device_health_check", "")
    writer = get_stream_writer()
    result = formulator_chain.invoke({"problem_description": translated_text})
    result = result.dict()
    device_names_en = result.get('device_names', [])
    result['device_names_cn'] = device_names_en
    if device_names_en:
        result['device_names_cn'] = [device_name_map[name] for name in device_names_en]
    markdown_text = (
        "#### æ–°å¥¥æ³›èƒ½ç½‘è™šæ‹Ÿç”µå‚éœ€æ±‚ä¾§å“åº”åˆ†é…ä¸è°ƒåº¦è®¡åˆ’ç”Ÿæˆ\n"
        "- [âœ”] éœ€æ±‚è½¬è¯‘ â€” å°†ç”¨æˆ·éœ€æ±‚è½¬è¯‘æˆè¿ç­¹ä¼˜åŒ–å¯ç†è§£çš„æè¿°æ–¹å¼\n"
        "- [âœ”] ç»“æ„åŒ–å¤„ç† â€” å°†éœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®\n"
        "- [ğŸŸ¡] ä»£ç ç”Ÿæˆ â€” æ ¹æ®è½¬è¯‘åçš„éœ€æ±‚ç”Ÿæˆä¼˜åŒ–æ¨¡å‹èƒ½åŠ›ä»£ç \n"
        "- [ ] ä»»åŠ¡æ±‚è§£ â€” æ‰§è¡Œä¼˜åŒ–æ±‚è§£ä»£ç ï¼Œå¾—åˆ°è°ƒåº¦ä¸åˆ†é…ç»“æœ\n"
        "- [ ] Reflection è‡ªæˆ‘ä¿®æ­£ â€” æ ¹æ®æ‰§è¡Œç»“æœå¯¹æ¨¡å‹ç”Ÿæˆçš„ä»£ç è¿›è¡Œè‡ªåŠ¨ä¿®æ­£\n"
        "- [ ] ç»“æœè§£é‡Š â€” å°†æ±‚è§£ç»“æœè½¬åŒ–ä¸ºç»“æ„åŒ–çš„ä¸­æ–‡è§£é‡Šä¸å¯è¯»è¾“å‡º\n"
        "- [ ] è°ƒåº¦è®¡åˆ’ç”Ÿæˆ â€” åŸºäºæ±‚è§£ç»“æœå’ŒåŸºçº¿æ•°æ®ï¼Œç”Ÿæˆæœ€ç»ˆçš„è°ƒåº¦ä¸åˆ†é…è®¡åˆ’\n"
    )
    writer({f"custom_text{str(uuid4())}": markdown_text})
    return {"formulation": result}


def smart_wrap_code(code: str, width: int = 60, indent: int = 4) -> str:
    """
    æ™ºèƒ½æ¢è¡Œä»£ç ï¼š
    - è‹±æ–‡å˜é‡åä¸æˆªæ–­
    - ä¸­æ–‡æ³¨é‡Šæ•´å¥æ¢è¡Œï¼ˆä¸æ‹†æˆå•å­—ï¼‰
    - é•¿å­—ç¬¦ä¸²åœ¨é€—å·ã€å†’å·ç­‰ç¬¦å·åä¼˜å…ˆæ¢è¡Œ
    """
    wrapped_lines = []
    for line in code.splitlines():
        # ä¸­æ–‡æ³¨é‡Šå¤„ç†
        if line.strip().startswith("#"):
            if len(line) <= width // 2:
                wrapped_lines.append(line)
                continue
            prefix = re.match(r"(\s*#\s*)", line).group(1)
            text = line[len(prefix):]
            wrapped = textwrap.wrap(
                text,
                width=width // 2 - len(prefix),
                break_long_words=True,   # å…è®¸æˆªæ–­é•¿è¿ç»­æ–‡æœ¬ï¼ˆä¸­æ–‡ï¼‰
                break_on_hyphens=False
            )
            wrapped_lines.extend([prefix + w for w in wrapped])
        else:
            if len(line) <= width:
                wrapped_lines.append(line)
                continue
            # æ™®é€šä»£ç ï¼šé¿å…å˜é‡è¢«æˆªæ–­
            line_mod = re.sub(r'([,:])', r'\1 ', line)
            wrapped = textwrap.wrap(
                line_mod,
                width=width,
                break_long_words=False,
                break_on_hyphens=False,
                subsequent_indent=" " * indent
            )
            wrapped_lines.extend(wrapped)

    return "\n".join(wrapped_lines)


def show_code(code_dict: dict, width: int = 60) -> str:
    """
    å°†ä»£ç å­—å…¸è½¬æ¢æˆ Markdown æ ¼å¼ï¼Œå¹¶å¯¹é•¿è¡Œè¿›è¡Œæ™ºèƒ½æ¢è¡Œ
    """
    imports = smart_wrap_code(code_dict.get("imports", ""), width=width)
    code = smart_wrap_code(code_dict.get("code", ""), width=width)
    return f"```python\n{imports}\n\n{code}\n```"


def coder_node(inputs: dict) -> dict:
    formulation = inputs.get("formulation", {})
    solver_error_info = inputs.get("solver_error_info", "")
    writer = get_stream_writer()
    result = coder_chain.invoke({
        "formulation_dict": formulation,
        "solver_path": local_solver_path,
        "solver_error_info": solver_error_info})
    markdown_text = (
        "#### æ–°å¥¥æ³›èƒ½ç½‘è™šæ‹Ÿç”µå‚éœ€æ±‚ä¾§å“åº”åˆ†é…ä¸è°ƒåº¦è®¡åˆ’ç”Ÿæˆ\n"
        "- [âœ”] éœ€æ±‚è½¬è¯‘ â€” å°†ç”¨æˆ·éœ€æ±‚è½¬è¯‘æˆè¿ç­¹ä¼˜åŒ–å¯ç†è§£çš„æè¿°æ–¹å¼\n"
        "- [âœ”] ç»“æ„åŒ–å¤„ç† â€” å°†éœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®\n"
        "- [âœ”] ä»£ç ç”Ÿæˆ â€” æ ¹æ®è½¬è¯‘åçš„éœ€æ±‚ç”Ÿæˆä¼˜åŒ–æ¨¡å‹èƒ½åŠ›ä»£ç \n"
        "- [ğŸŸ¡] ä»»åŠ¡æ±‚è§£ â€” æ‰§è¡Œä¼˜åŒ–æ±‚è§£ä»£ç ï¼Œå¾—åˆ°è°ƒåº¦ä¸åˆ†é…ç»“æœ\n"
        "- [ ] ç»“æœè§£é‡Š â€” å°†æ±‚è§£ç»“æœè½¬åŒ–ä¸ºç»“æ„åŒ–çš„ä¸­æ–‡è§£é‡Šä¸å¯è¯»è¾“å‡º\n"
        "- [ ] Reflection è‡ªæˆ‘ä¿®æ­£ â€” æ ¹æ®æ‰§è¡Œç»“æœå¯¹æ¨¡å‹ç”Ÿæˆçš„ä»£ç è¿›è¡Œè‡ªåŠ¨ä¿®æ­£\n"
        "- [ ] è°ƒåº¦è®¡åˆ’ç”Ÿæˆ â€” åŸºäºæ±‚è§£ç»“æœå’ŒåŸºçº¿æ•°æ®ï¼Œç”Ÿæˆæœ€ç»ˆçš„è°ƒåº¦ä¸åˆ†é…è®¡åˆ’\n"
    )
    writer({f"custom_text{str(uuid4())}": markdown_text})
    markdown_code = show_code(result.dict())
    writer({f"custom_text{str(uuid4())}": markdown_code})
    return {"code_output": result.dict()}


def solver_node(inputs: dict) -> dict:
    code_output = inputs.get("code_output", {})
    imports = code_output.get("imports", "")
    code = code_output.get("code", "")

    writer = get_stream_writer()

    # print(imports + "\n" + code)

    f = io.StringIO()
    context = {"__builtins__": __builtins__}  # ç¡®ä¿ Python å†…ç½®å¯ç”¨
    try:
        with redirect_stdout(f):
            exec(imports + "\n" + code, context, context)
        raw_out = f.getvalue()
        result = SolverOutput(raw_output=raw_out)
        markdown_text = (
            "#### æ–°å¥¥æ³›èƒ½ç½‘è™šæ‹Ÿç”µå‚éœ€æ±‚ä¾§å“åº”åˆ†é…ä¸è°ƒåº¦è®¡åˆ’ç”Ÿæˆ\n"
            "- [âœ”] éœ€æ±‚è½¬è¯‘ â€” å°†ç”¨æˆ·éœ€æ±‚è½¬è¯‘æˆè¿ç­¹ä¼˜åŒ–å¯ç†è§£çš„æè¿°æ–¹å¼\n"
            "- [âœ”] ç»“æ„åŒ–å¤„ç† â€” å°†éœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®\n"
            "- [âœ”] ä»£ç ç”Ÿæˆ â€” æ ¹æ®è½¬è¯‘åçš„éœ€æ±‚ç”Ÿæˆä¼˜åŒ–æ¨¡å‹èƒ½åŠ›ä»£ç \n"
            "- [âœ”] ä»»åŠ¡æ±‚è§£ â€” æ‰§è¡Œä¼˜åŒ–æ±‚è§£ä»£ç ï¼Œå¾—åˆ°è°ƒåº¦ä¸åˆ†é…ç»“æœ\n"
            "- [ğŸŸ¡] ç»“æœè§£é‡Š â€” å°†æ±‚è§£ç»“æœè½¬åŒ–ä¸ºç»“æ„åŒ–çš„ä¸­æ–‡è§£é‡Šä¸å¯è¯»è¾“å‡º\n"
            "- [ ] Reflection è‡ªæˆ‘ä¿®æ­£ â€” æ ¹æ®æ‰§è¡Œç»“æœå¯¹æ¨¡å‹ç”Ÿæˆçš„ä»£ç è¿›è¡Œè‡ªåŠ¨ä¿®æ­£\n"
            "- [ ] è°ƒåº¦è®¡åˆ’ç”Ÿæˆ â€” åŸºäºæ±‚è§£ç»“æœå’ŒåŸºçº¿æ•°æ®ï¼Œç”Ÿæˆæœ€ç»ˆçš„è°ƒåº¦ä¸åˆ†é…è®¡åˆ’\n"
        )
        writer({f"custom_text{str(uuid4())}": markdown_text})
        return {"solution": result.dict(), "solver_error_info": ""}
    except Exception as e:
        error_message = str(e)
        raw_out = f.getvalue()
        return {
            "solution": {"raw_output": f"Execution error: {error_message}\n{raw_out}"},
            "solver_error_info": error_message
        }


def interpreter_node(inputs: dict) -> dict:
    solution_text = inputs.get("solution", {}).get("raw_output", "")
    device_names = inputs.get("formulation", {}).get("device_names", [])

    try:
        result = interpreter_chain.invoke({
            "solution": solution_text,
            "device_names": device_names
        })
        parsed = result.dict()
        response_allocation = []
        variables = parsed.get("variables", [])
        if variables:
            response_allocation = [{"name": device_name_map[ele["name"]], "value": ele["value"]} for ele in variables]
        return {
            "interpretation": {
                "status": parsed.get("status", "unknown"),
                "variables": variables,
                "response_allocation": response_allocation,
                "interpretation": parsed.get("interpretation", "No interpretation provided")
            }
        }
    except Exception as e:
        return {
            "interpretation": {
                "status": "error",
                "variables": [],
                "response_allocation": [],
                "interpretation": f"Error during interpretation: {e}"
            }
        }


def generate_dr_plan(
        response_alloc: dict,
        response_cost: dict,
        start_time: str = "16:00:00",
        end_time: str = "17:00:00",
        sampling_frequency: float = 0.25,
        response_price: float = 3.0
):
    if not response_cost: response_cost = {k: 0 for k, v in response_alloc.items()}
    # ï¼ˆæ­¤å¤„ç•¥ï¼Œä½¿ç”¨ä½ ä¹‹å‰çš„å®Œæ•´generate_dr_planå‡½æ•°å®ç°ï¼‰
    rated_power = {'ESS_HBN': 1200, 'ESS_HY': 1500, 'ESS_ML': 1300}
    df = pd.read_csv(csv_path)
    df['time'] = pd.to_datetime(df['time'])
    full_data = df.copy()
    mask = (df['time'].dt.strftime("%H:%M:%S") >= start_time) & (df['time'].dt.strftime("%H:%M:%S") < end_time)
    response_window = df.loc[mask].copy()
    intervals = len(response_window)

    ori_response_alloc = copy.deepcopy(response_alloc)
    # å•ä½MW --> KW
    response_alloc = {k: v * 1000 * intervals for k, v in response_alloc.items()}

    json_plan = {"VPP_Response_Plan": []}

    for device, alloc in response_alloc.items():
        baseline_dict = {
            "time": [t.strftime("%H:%M:%S") for t in df['time']],
            "value": [float(round(v, 2)) for v in df[device].tolist()]  # âœ… è½¬ä¸º float
        }
        new_values_full = df[device].tolist()
        if device == "PV":
            pass
        elif device == "EV":
            if alloc > 0:
                for i in response_window.index:
                    new_values_full[i] = 0.0
        elif device == "HVAC":
            reduce_each = alloc / intervals
            for i in response_window.index:
                new_values_full[i] = max(0, df.loc[i, device] - reduce_each)
        elif device in ["ESS_HBN", "ESS_HY", "ESS_ML"]:
            max_power = rated_power[device]
            baseline_power = df.loc[response_window.index, device].tolist()
            available = []
            for v in baseline_power:
                if v < 0:
                    available.append(abs(v))
                else:
                    available.append(max_power - v if v < max_power else 0)
            if sum(available) == 0:
                increments = [0.0] * intervals
            else:
                increments = [(a / sum(available)) * alloc for a in available]
            for idx, (i, inc) in enumerate(zip(response_window.index, increments)):
                v = df.loc[i, device]
                if v < 0:
                    adjust = min(abs(v), inc)
                    new_values_full[i] = v + adjust
                    leftover = inc - adjust
                    if leftover > 0:
                        new_values_full[i] = min(max_power, new_values_full[i] + leftover)
                else:
                    new_values_full[i] = min(max_power, v + inc)
                new_values_full[i] = round(new_values_full[i], 2)
        full_data[device] = new_values_full
        response_dict = {
            "time": [t.strftime("%H:%M:%S") for t in df['time']],
            "value": [float(round(v, 2)) for v in new_values_full]  # âœ… è½¬ä¸º float
        }
        json_plan["VPP_Response_Plan"].append({
            "device_id": device,
            "device_name": device_name_map[device],
            "response_info": {
                "allocated_amount": ori_response_alloc[device],
                "baseline": baseline_dict,
                "response_plan": response_dict,
                "response_price": response_price,
                "response_profit": round((response_price - response_cost[device]) * ori_response_alloc[device] * 1000, 2)
            }
        })
    return json_plan


def plan_node(state: dict) -> dict:
    interpretation = state.get("interpretation", {})
    variables = interpretation.get("variables", [])
    response_cost = state.get("formulation", {}).get("response_cost", [])
    device_names = state.get("formulation", {}).get("device_names", [])

    writer = get_stream_writer()

    if len(response_cost) == len(device_names):
        response_cost_dict = dict(zip(device_names, response_cost))
    else:
        response_cost_dict = {}
    if not variables:
        plan = {"error": "No variables found in interpretation"}
    else:
        response_alloc = {item["name"]: float(item["value"]) for item in variables}
        plan = generate_dr_plan(response_alloc=response_alloc, response_cost=response_cost_dict)

    # æ›´æ–°çŠ¶æ€ä¸­çš„å†å²è®¡åˆ’åˆ—è¡¨
    plans = state.get("plans", [])
    plans.append(plan)

    markdown_text = (
        "#### æ–°å¥¥æ³›èƒ½ç½‘è™šæ‹Ÿç”µå‚éœ€æ±‚ä¾§å“åº”åˆ†é…ä¸è°ƒåº¦è®¡åˆ’ç”Ÿæˆ\n"
        "- [âœ”] éœ€æ±‚è½¬è¯‘ â€” å°†ç”¨æˆ·éœ€æ±‚è½¬è¯‘æˆè¿ç­¹ä¼˜åŒ–å¯ç†è§£çš„æè¿°æ–¹å¼\n"
        "- [âœ”] ç»“æ„åŒ–å¤„ç† â€” å°†éœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®\n"
        "- [âœ”] ä»£ç ç”Ÿæˆ â€” æ ¹æ®è½¬è¯‘åçš„éœ€æ±‚ç”Ÿæˆä¼˜åŒ–æ¨¡å‹èƒ½åŠ›ä»£ç \n"
        "- [âœ”] ä»»åŠ¡æ±‚è§£ â€” æ‰§è¡Œä¼˜åŒ–æ±‚è§£ä»£ç ï¼Œå¾—åˆ°è°ƒåº¦ä¸åˆ†é…ç»“æœ\n"
        "- [âœ”] ç»“æœè§£é‡Š â€” å°†æ±‚è§£ç»“æœè½¬åŒ–ä¸ºç»“æ„åŒ–çš„ä¸­æ–‡è§£é‡Šä¸å¯è¯»è¾“å‡º\n"
        "- [âœ”] Reflection è‡ªæˆ‘ä¿®æ­£ â€” æ ¹æ®æ‰§è¡Œç»“æœå¯¹æ¨¡å‹ç”Ÿæˆçš„ä»£ç è¿›è¡Œè‡ªåŠ¨ä¿®æ­£\n"
        "- [âœ”] è°ƒåº¦è®¡åˆ’ç”Ÿæˆ â€” åŸºäºæ±‚è§£ç»“æœå’ŒåŸºçº¿æ•°æ®ï¼Œç”Ÿæˆæœ€ç»ˆçš„è°ƒåº¦ä¸åˆ†é…è®¡åˆ’\n"
    )
    writer({f"custom_text{str(uuid4())}": markdown_text})

    # è¿”å›æ›´æ–°çš„ plan å’Œ plans
    return {"plans": plans}


def get_p_temperature_curve(ratedPower, x, t0=20, t1=32):
    """
    åŠŸç‡ä¸æ¸©åº¦çš„å…³ç³»æ›²çº¿
    """
    T = t0 + (t1 - t0) * (1 + np.tanh(-(x - ratedPower / 2) / ratedPower * 4)) / 2
    return T


# def get_p_by_temperature(T_max, ratedPower=800, t0=25, t1=35):
#     """
#     æ ¹æ®æœ«ç«¯ç¨³æ€æ¸©åº¦è¿”å›å¯¹åº”åŠŸç‡
#     """
#     for x in range(0, ratedPower + 1, 100):
#         if get_p_temperature_curve(ratedPower, x, t0, t1) <= T_max:
#             return x
#     return ratedPower

def get_p_by_temperature(T_max, ratedPower=20000, t0=20, t1=32):
    """
    æ ¹æ®æœ«ç«¯ç¨³æ€æ¸©åº¦è¿”å›å¯¹åº”åŠŸç‡
    """
    for x in range(0, ratedPower + 1, 100):
        if get_p_temperature_curve(ratedPower, x, t0, t1) <= T_max:
            return x
    return ratedPower


def compute_delta(temperature, baseline_temp=30, ratedPower=20000):
    P0 = get_p_by_temperature(baseline_temp, ratedPower)
    P1 = get_p_by_temperature(temperature, ratedPower)
    return (P1 - P0) / 1000  # è½¬MW


def retry_manager_node(inputs: dict) -> dict:
    valid = inputs.get("valid", True)
    reason = inputs.get("reason", "")
    retry_count = inputs.get("retry_count", 0)

    writer = get_stream_writer()

    if not valid:
        retry_count += 1
        if retry_count <= MaxRetryCount:
            return {"retry": True, "retry_count": retry_count, "solver_error_info": reason}
        else:
            return {"retry": False, "retry_count": retry_count, "solver_error_info": reason}
    markdown_text = (
        "#### æ–°å¥¥æ³›èƒ½ç½‘è™šæ‹Ÿç”µå‚éœ€æ±‚ä¾§å“åº”åˆ†é…ä¸è°ƒåº¦è®¡åˆ’ç”Ÿæˆ\n"
        "- [âœ”] éœ€æ±‚è½¬è¯‘ â€” å°†ç”¨æˆ·éœ€æ±‚è½¬è¯‘æˆè¿ç­¹ä¼˜åŒ–å¯ç†è§£çš„æè¿°æ–¹å¼\n"
        "- [âœ”] ç»“æ„åŒ–å¤„ç† â€” å°†éœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®\n"
        "- [âœ”] ä»£ç ç”Ÿæˆ â€” æ ¹æ®è½¬è¯‘åçš„éœ€æ±‚ç”Ÿæˆä¼˜åŒ–æ¨¡å‹èƒ½åŠ›ä»£ç \n"
        "- [âœ”] ä»»åŠ¡æ±‚è§£ â€” æ‰§è¡Œä¼˜åŒ–æ±‚è§£ä»£ç ï¼Œå¾—åˆ°è°ƒåº¦ä¸åˆ†é…ç»“æœ\n"
        "- [âœ”] ç»“æœè§£é‡Š â€” å°†æ±‚è§£ç»“æœè½¬åŒ–ä¸ºç»“æ„åŒ–çš„ä¸­æ–‡è§£é‡Šä¸å¯è¯»è¾“å‡º\n"
        "- [âœ”] Reflection è‡ªæˆ‘ä¿®æ­£ â€” æ ¹æ®è‡ªæ£€ç»“æœå¯¹æ¨¡å‹ç”Ÿæˆçš„ä»£ç è¿›è¡Œè‡ªåŠ¨ä¿®æ­£\n"
        "- [ğŸŸ¡] è°ƒåº¦è®¡åˆ’ç”Ÿæˆ â€” åŸºäºæ±‚è§£ç»“æœå’ŒåŸºçº¿æ•°æ®ï¼Œç”Ÿæˆæœ€ç»ˆçš„è°ƒåº¦ä¸åˆ†é…è®¡åˆ’\n"
    )
    writer({f"custom_text{str(uuid4())}": markdown_text})
    return {"retry": False, "retry_count": retry_count}


def interpretation_validator_node(inputs: dict) -> dict:
    interpretation = inputs.get("interpretation", {})
    solver_error_info = inputs.get("solver_error_info", "")

    writer = get_stream_writer()

    result = interpretation_validator_chain.invoke({
        "solver_error_info": solver_error_info,
        "interpretation": interpretation
    })

    markdown_text = (
        "#### æ–°å¥¥æ³›èƒ½ç½‘è™šæ‹Ÿç”µå‚éœ€æ±‚ä¾§å“åº”åˆ†é…ä¸è°ƒåº¦è®¡åˆ’ç”Ÿæˆ\n"
        "- [âœ”] éœ€æ±‚è½¬è¯‘ â€” å°†ç”¨æˆ·éœ€æ±‚è½¬è¯‘æˆè¿ç­¹ä¼˜åŒ–å¯ç†è§£çš„æè¿°æ–¹å¼\n"
        "- [âœ”] ç»“æ„åŒ–å¤„ç† â€” å°†éœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®\n"
        "- [âœ”] ä»£ç ç”Ÿæˆ â€” æ ¹æ®è½¬è¯‘åçš„éœ€æ±‚ç”Ÿæˆä¼˜åŒ–æ¨¡å‹èƒ½åŠ›ä»£ç \n"
        "- [âœ”] ä»»åŠ¡æ±‚è§£ â€” æ‰§è¡Œä¼˜åŒ–æ±‚è§£ä»£ç ï¼Œå¾—åˆ°è°ƒåº¦ä¸åˆ†é…ç»“æœ\n"
        "- [âœ”] ç»“æœè§£é‡Š â€” å°†æ±‚è§£ç»“æœè½¬åŒ–ä¸ºç»“æ„åŒ–çš„ä¸­æ–‡è§£é‡Šä¸å¯è¯»è¾“å‡º\n"
        "- [ğŸŸ¡] Reflection è‡ªæˆ‘ä¿®æ­£ â€” æ ¹æ®æ‰§è¡Œç»“æœå¯¹æ¨¡å‹ç”Ÿæˆçš„ä»£ç è¿›è¡Œè‡ªåŠ¨ä¿®æ­£\n"
        "- [ ] è°ƒåº¦è®¡åˆ’ç”Ÿæˆ â€” åŸºäºæ±‚è§£ç»“æœå’ŒåŸºçº¿æ•°æ®ï¼Œç”Ÿæˆæœ€ç»ˆçš„è°ƒåº¦ä¸åˆ†é…è®¡åˆ’\n"
    )
    writer({f"custom_text{str(uuid4())}": markdown_text})

    return result.dict()  # {"valid": bool, "reason": str}


def get_baselines():
    """
    åŸºçº¿é¢„æµ‹èŠ‚ç‚¹ï¼šä»æœ¬åœ°CSVè¯»å–æ•°æ®ï¼Œè¿”å›æŒ‡å®šç»“æ„ã€‚

    CSVå­—æ®µç¤ºä¾‹ï¼š
    time    HVAC    ESS_HBN ESS_ML  ESS_HY  PV  EV
    2025-08-04 00:00:00    10    5   2   3   100  20
    """
    # è¯»å–CSV
    df = pd.read_csv(csv_path)

    # ç¡®è®¤åŒ…å« time å­—æ®µ
    if 'time' not in df.columns:
        raise ValueError("CSVæ–‡ä»¶ç¼ºå°‘ time å­—æ®µ")

    # è®¾å¤‡å­—æ®µï¼ˆæ’é™¤ timeï¼‰
    device_columns = [col for col in df.columns if col != 'time']

    baselines = []

    # éå†æ¯ä¸ªè®¾å¤‡
    for device in device_columns:
        device_data = {
            "device_name": device_name_map[device],
            "baseline": {
                "times": df['time'].tolist(),
                "value": df[device].tolist()
            }
        }
        baselines.append(device_data)

    return baselines


def baseline_node(state: dict) -> dict:
    state["baselines"] = get_baselines()
    from src.utils.extra_tools import generate_echarts_config
    baselines = get_baselines()
    x_data = []
    baseline_list = []
    for baseline in baselines:
        name = baseline["device_name"]
        x_data = baseline["baseline"]["times"]
        baseline_values = baseline["baseline"]["value"]
        each = {"name": name + "_baseline", "data": baseline_values}
        baseline_list.append(each)
    baseline_curve = generate_echarts_config("åŸºçº¿æ›²çº¿", chart_type="line", x_data=x_data, series_list=baseline_list)
    writer = get_stream_writer()
    writer({f"custom_text{str(uuid4())}": f"""{baseline_curve}"""})
    return state


